
<h1 align="center">âœ‹ YOLOv8 Hand Gesture Detection App ğŸ¤–ğŸ¥</h1>

<p align="center">
A <strong>real-time Computer Vision project</strong> that detects and classifies <strong>multiple hand gestures</strong> using <code>YOLOv8 (Ultralytics)</code> and a <code>Streamlit Web Interface</code>.
</p>

---

ğŸš€ <strong>Built with Python, OpenCV, and Streamlit</strong>, this project demonstrates <em>object detection</em>, <em>custom model training</em>, and <em>web app deployment</em>.

---

## ğŸ“Œ Key Features

- âœ… Real-time <strong>Webcam Stream Detection</strong>
- âœ… <strong>Multi-class Hand Gesture Recognition</strong> (Like ğŸ‘ğŸ» Peace âœŒğŸ» Stop ğŸ›‘ Rock ğŸ¤˜ğŸ» etc.)
- âœ… Emoji-based <strong>visual representation</strong> for each gesture
- âœ… <strong>Streamlit UI</strong> for easy interaction
- âœ… <strong>Custom trained YOLOv8 model</strong> with 16 gesture classes
- âœ… Deployable on <strong>Streamlit Cloud</strong> or <strong>Hugging Face Spaces</strong>

---

## ğŸ“Š Problem Statement

In the field of <strong>Human-Computer Interaction (HCI)</strong>, <strong>contactless control</strong> using gestures is becoming essential for:

- ğŸ¤– AI-controlled interfaces  
- âœ‹ Sign Language Recognition  
- ğŸ® Virtual Gaming  
- ğŸ“± Smart Devices  

This app enables detection of gestures like:

| Gesture | Emoji |
|--------|-------|
| Peace  | âœŒğŸ»   |
| Like   | ğŸ‘ğŸ»  |
| Dislike| ğŸ‘ğŸ»  |
| Stop   | ğŸ›‘    |
| Rock   | ğŸ¤˜ğŸ»  |
| Fist   | âœŠğŸ»   |
| One    | â˜ğŸ»   |
| Palm   | ğŸ«±ğŸ»  |

_(You can add more gesture classes based on your dataset)_

---

## ğŸ§  Tech Stack

| Domain                  | Tools Used                          |
|------------------------|-------------------------------------|
| Language                | Python                              |
| Deep Learning Framework | YOLOv8 (Ultralytics)                |
| Libraries               | OpenCV, PIL, Streamlit, Ultralytics |
| UI Framework            | Streamlit                           |
| Model Format            | YOLOv8 `.pt` weights                |
| Deployment Ready?       | âœ… Yes                               |

---

## ğŸ“ˆ Model Training Summary

| Metric                  | Value  |
|-------------------------|--------|
| Total Training Images   | 9,948  |
| Total Validation Images | 449    |
| Total Epochs            | 33     |
| Precision               | 98.85% |
| Recall                  | 98.69% |
| mAP@0.5                 | 99.37% |
| mAP@0.5:0.95            | 85.51% |

âœ… Training performed on a <strong>custom hand gesture dataset with 16 classes</strong>

---

## ğŸš€ How to Run Locally

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/karthik-lakkimsetti/YOLOv8-Hand-Gesture-Detection-App.git
cd YOLOv8-Hand-Gesture-Detection-App
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv yolov8
.\yolov8\Scriptsctivate   # On Windows
```

### 3ï¸âƒ£ Install Required Libraries

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add Your YOLOv8 Model Weights

Place your YOLOv8 `.pt` file (e.g., `best.pt`) in the project directory.  
Then update the path in `app.py`:

```python
model = YOLO('path/to/your/best.pt')
```

### 5ï¸âƒ£ Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ“ Folder Structure

```bash
YOLOv8-Hand-Gesture-Detection-App/
â”œâ”€â”€ app.py                  # Streamlit app
â”œâ”€â”€ training.py             # YOLOv8 training script
â”œâ”€â”€ Pretrained yolov8s.py   # Sample inference (optional)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Ignored files/folders
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ yolov8/                 # Virtual environment (ignored)
â”œâ”€â”€ data/                   # Custom dataset (ignored)
â””â”€â”€ runs/                   # YOLO training outputs (ignored)
```

---

## âœ… Skills Showcased

- ğŸ¯ Real-time Computer Vision using YOLOv8  
- ğŸ” Custom Object Detection Model Training  
- ğŸŒ Streamlit Web App Development  
- ğŸ§± Clean Python Project Structuring  
- ğŸ§  Model Training and Metrics Tracking  
- â˜ï¸ Ready for Deployment  
- ğŸ’» Version Control with Git & GitHub  

---

## ğŸ’¡ Future Improvements

- â˜ï¸ Deploy on **Streamlit Cloud** or **Hugging Face Spaces**
- ğŸ“¹ Support for **video file gesture detection**
- ğŸ§ª Add **Jupyter Notebook** walkthrough for training
- âœ¨ Enhance UI with Streamlit custom components
- ğŸ¤Ÿ Extend to full **ASL gesture recognition**

---

## ğŸ¤ Let's Connect

ğŸ“§ Email: [karthiksrivardhan45@gmail.com](mailto:karthiksrivardhan45@gmail.com)  
ğŸ”— LinkedIn: [Karthik Sri Vardhan](https://www.linkedin.com/in/karthik-sri-vardhan/)  
ğŸŒ GitHub: [@karthik-lakkimsetti](https://github.com/karthik-lakkimsetti)
